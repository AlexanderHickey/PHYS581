
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{Assignment 5}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \hypertarget{phys-581-winter-2019}{%
\section{Phys 581 Winter 2019}\label{phys-581-winter-2019}}

\hypertarget{assignment-5-multiprocessing}{%
\section{Assignment \#5:
Multiprocessing}\label{assignment-5-multiprocessing}}

\hypertarget{alexander-hickey-10169582}{%
\subsection{Alexander Hickey,
10169582}\label{alexander-hickey-10169582}}

    Note that this notebook makes use of the Keras deep learning library for
python, which is compatible only with Python 2.7-3.6.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}1}]:} \PY{c+c1}{\PYZsh{}Must be running Python 3.6 or lower!}
        \PY{k+kn}{import} \PY{n+nn}{sys}
        \PY{n}{sys}\PY{o}{.}\PY{n}{version}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}1}]:} '3.6.8 |Anaconda, Inc.| (default, Dec 30 2018, 01:22:34) \textbackslash{}n[GCC 7.3.0]'
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{c+c1}{\PYZsh{}Import useful libraries}
        \PY{k+kn}{import} \PY{n+nn}{time}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{integrate}
        \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        \PY{k+kn}{import} \PY{n+nn}{subprocess}
        \PY{k+kn}{import} \PY{n+nn}{psutil}
        \PY{k+kn}{from} \PY{n+nn}{multiprocessing} \PY{k}{import} \PY{n}{Pool}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{models} \PY{k}{import} \PY{n}{Model}\PY{p}{,} \PY{n}{Sequential}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers} \PY{k}{import} \PY{n}{Input}\PY{p}{,} \PY{n}{Dense}
        \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Using TensorFlow backend.

    \end{Verbatim}

    \hypertarget{introduction}{%
\subsubsection{Introduction}\label{introduction}}

    Parallel computing allows one to harness the processing power of a
multi-core computer, and can significantly decrease the time required
for repetitive computations. The idea behind parallel computing is to
take a large problem and divide it into smaller ones which can be solved
simultaneously, and allocate these different tasks to different parts of
the CPU network. Often times, it is very powerful to implement parallel
computing in the framework of scientific computations, to allow
researchers to execute code and analyze output within a reasonable
timeframe.

The goal of this notebook is to analyze the process of parallel
computing in python, and the efficiency of distributing tasks across a
multi-core processor. In particular, I will look at how the
computational efficiency scales with the number of computationally
intensive tasks, as well as how parallel computing can be used in the
context of hyperparameter optimization for machine learning.

To analyze in detail how parallel processes get distributed over a
multi-core processor, we will use the psutil library, which is used to
retrieve information about running processes and system utilization
(CPU, memory, disks, network, sensors) in Python. For hyperparameter
optimization, we will use the multiprocessing package. For example, the
psutil can be used to determine the number of cores on a given device.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{n+nb}{print}\PY{p}{(} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{number of physical cores: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{psutil}\PY{o}{.}\PY{n}{cpu\PYZus{}count}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}} \PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
number of physical cores:  4 


    \end{Verbatim}

    For referece, this notebook is being developped on one of the Linux
machines in the PJL, each of which contains 4 cores.

    \hypertarget{task-determine-scaling-efficiency}{%
\subsubsection{Task: determine scaling
efficiency}\label{task-determine-scaling-efficiency}}

    The psutil library allows one to calculate the total CPU time spend on a
task. To determine the scaling efficiency, we will compare this time to
the so called wall time, which is the actual time elapsed. To start, we
define some task that will be spawned multiple times in parallel.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{c+c1}{\PYZsh{}Define some arbitrary CPU intensive task to be run in the terminal}
        \PY{n}{cmnd} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{python \PYZhy{}c }\PY{l+s+s1}{\PYZdq{}}\PY{l+s+s1}{[i**2 for i in range(9876543)]}\PY{l+s+s1}{\PYZdq{}}\PY{l+s+s1}{\PYZsq{}}
\end{Verbatim}


    Next, we define the function that will compute both the CPU and wall
time for some set of processes that are spawned simultaneously.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{k}{def} \PY{n+nf}{time\PYZus{}par}\PY{p}{(}\PY{n}{cmdlist}\PY{p}{,} \PY{n}{time\PYZus{}res} \PY{o}{=} \PY{l+m+mf}{1e\PYZhy{}5}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}}
        \PY{l+s+sd}{    This function will compute both the CPU and wall time for a set}
        \PY{l+s+sd}{    of processes spawned simultaneously.}
        \PY{l+s+sd}{    }
        \PY{l+s+sd}{    Args:}
        \PY{l+s+sd}{        cmdlist: List of commands to track}
        \PY{l+s+sd}{        time\PYZus{}res: Time step between tracking}
        \PY{l+s+sd}{        }
        \PY{l+s+sd}{    Return:}
        \PY{l+s+sd}{        tlist: Array of both wall and cpu times for each process}
        \PY{l+s+sd}{               to terminate. Axis 0 corresponds to wall time,}
        \PY{l+s+sd}{               axis 1 corresponds to cpu time.}
        \PY{l+s+sd}{    }
        \PY{l+s+sd}{    \PYZsq{}\PYZsq{}\PYZsq{}}
            
            \PY{c+c1}{\PYZsh{}Spawn each process using the subprocess module.}
            \PY{n}{plist} \PY{o}{=} \PY{p}{[}\PY{n}{subprocess}\PY{o}{.}\PY{n}{Popen}\PY{p}{(}\PY{n}{cmnd}\PY{p}{,} \PY{n}{shell}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)} \PY{k}{for} \PY{n}{j} \PY{o+ow}{in} \PY{n}{cmdlist}\PY{p}{]}
            
            \PY{c+c1}{\PYZsh{}Iitialize list of child processes and wall time}
            \PY{n}{ch\PYZus{}list} \PY{o}{=} \PY{p}{[}\PY{l+m+mf}{0.0}\PY{p}{]} 
            \PY{n}{t0} \PY{o}{=} \PY{n}{time}\PY{o}{.}\PY{n}{time}\PY{p}{(}\PY{p}{)}
            
            \PY{c+c1}{\PYZsh{}Initialize dictionary that tracks CPU time while}
            \PY{c+c1}{\PYZsh{}processes are still running.}
            \PY{n}{t\PYZus{}dict} \PY{o}{=} \PY{p}{\PYZob{}}\PY{n}{p}\PY{o}{.}\PY{n}{pid}\PY{p}{:}\PY{l+m+mf}{0.0} \PY{k}{for} \PY{n}{p} \PY{o+ow}{in} \PY{n}{plist}\PY{p}{\PYZcb{}}
            
            
            \PY{c+c1}{\PYZsh{}Empty list of child processes signals all of them have terminated}
            \PY{k}{while} \PY{n}{ch\PYZus{}list} \PY{o}{!=} \PY{p}{[}\PY{p}{]}\PY{p}{:}
                
                \PY{n}{ch\PYZus{}list} \PY{o}{=} \PY{p}{[}\PY{p}{]}
                
                \PY{c+c1}{\PYZsh{}Pause for timestep}
                \PY{n}{time}\PY{o}{.}\PY{n}{sleep}\PY{p}{(}\PY{n}{time\PYZus{}res}\PY{p}{)}
                
                \PY{c+c1}{\PYZsh{}Record wall/cpu time of each process if still running}
                \PY{k}{for} \PY{n}{p} \PY{o+ow}{in} \PY{n}{plist}\PY{p}{:}    
                    
                    \PY{n}{child} \PY{o}{=} \PY{n}{psutil}\PY{o}{.}\PY{n}{Process}\PY{p}{(}\PY{n}{pid}\PY{o}{=}\PY{n}{p}\PY{o}{.}\PY{n}{pid}\PY{p}{)}\PY{o}{.}\PY{n}{children}\PY{p}{(}\PY{p}{)}
                    
                    \PY{c+c1}{\PYZsh{}Try to get info on process, if process has}
                    \PY{c+c1}{\PYZsh{}terminated, psutil will return an exception error}
                    \PY{k}{try}\PY{p}{:}
                        
                        \PY{c+c1}{\PYZsh{}Record cpu time of process}
                        \PY{n}{proc} \PY{o}{=} \PY{n}{psutil}\PY{o}{.}\PY{n}{Process}\PY{p}{(}\PY{n}{pid}\PY{o}{=}\PY{n}{child}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{pid}\PY{p}{)}
                        \PY{n}{cputime} \PY{o}{=} \PY{n}{proc}\PY{o}{.}\PY{n}{cpu\PYZus{}times}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{user}
                        
                        \PY{c+c1}{\PYZsh{}Record wall/cpu times in dictionary}
                        \PY{n}{t\PYZus{}dict}\PY{p}{[}\PY{n}{p}\PY{o}{.}\PY{n}{pid}\PY{p}{]} \PY{o}{=} \PY{p}{[}\PY{n}{time}\PY{o}{.}\PY{n}{time}\PY{p}{(}\PY{p}{)}\PY{o}{\PYZhy{}}\PY{n}{t0}\PY{p}{,}\PY{n}{cputime}\PY{p}{]}
                        
                        \PY{c+c1}{\PYZsh{}Append to list of active processes}
                        \PY{n}{ch\PYZus{}list}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{child}\PY{p}{)}
                        
                    \PY{k}{except}\PY{p}{:}
                        \PY{k+kc}{None}
            
            
            \PY{k}{return} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{n}{t\PYZus{}dict}\PY{p}{[}\PY{n}{key}\PY{p}{]} \PY{k}{for} \PY{n}{key} \PY{o+ow}{in} \PY{n}{t\PYZus{}dict} \PY{p}{]}\PY{p}{)}
        
        \PY{k}{def} \PY{n+nf}{ratio}\PY{p}{(}\PY{n}{t}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}}
        \PY{l+s+sd}{    This function will compute the ratio of the average CPU time}
        \PY{l+s+sd}{    per process to the total wall time.}
        \PY{l+s+sd}{    }
        \PY{l+s+sd}{    Args:}
        \PY{l+s+sd}{        t: Array of both wall and cpu times. Axis 0 corresponds to wall time,}
        \PY{l+s+sd}{            axis 1 corresponds to cpu time.}
        \PY{l+s+sd}{        }
        \PY{l+s+sd}{    Return:}
        \PY{l+s+sd}{        tlist: Average CPU time divided by total wall time.}
        \PY{l+s+sd}{    }
        \PY{l+s+sd}{    \PYZsq{}\PYZsq{}\PYZsq{}}
            
            \PY{k}{return} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{t}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{o}{/}\PY{n}{np}\PY{o}{.}\PY{n}{max}\PY{p}{(}\PY{n}{t}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    Next, we look at how this efficiency scales with the number of processes
given to the terminal.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{n}{N} \PY{o}{=} \PY{l+m+mi}{15}
        \PY{n}{t\PYZus{}rat} \PY{o}{=} \PY{p}{[}\PY{p}{]}
        
        \PY{k}{for} \PY{n}{k} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,}\PY{n}{N}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{:}
            
            \PY{c+c1}{\PYZsh{}Compute CPU/wall time}
            \PY{n}{t} \PY{o}{=} \PY{n}{time\PYZus{}par}\PY{p}{(}\PY{p}{[}\PY{n}{cmnd} \PY{k}{for} \PY{n}{j} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{k}\PY{p}{)}\PY{p}{]}\PY{p}{)}
            \PY{n}{t\PYZus{}rat}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{ratio}\PY{p}{(}\PY{n}{t}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{6}\PY{p}{)}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,}\PY{n}{N}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,}\PY{n}{t\PYZus{}rat}\PY{p}{,}\PY{n}{marker} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{o}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Number of processes}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{fontsize} \PY{o}{=} \PY{l+m+mi}{18}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Average CPU time/Total wall time}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{fontsize} \PY{o}{=} \PY{l+m+mi}{18}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Parallel process scaling efficiency}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{fontsize} \PY{o}{=} \PY{l+m+mi}{18}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_15_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    We see that the average CPU time relative to the total wall time tends
to decrease with the total number of processes. This is to be expected,
as all of the processes are spawned simultaneously. Furthermore, we see
that the efficiency tends to asymptote for large numbers of tasks,
suggesting that the multi-core CPU eventually becomes saturated, in
which case some of the tasks will need to wait for available memory to
execute.

    \hypertarget{task-use-the-multiprocessing-package-to-speed-up-hyperparameter-optimization.}{%
\subsubsection{Task: Use the multiprocessing package to speed up
hyperparameter
optimization.}\label{task-use-the-multiprocessing-package-to-speed-up-hyperparameter-optimization.}}

    Next we will look at how the multiprocessing package can be used to
speed up hyperparameter optimizations. Recall from the Neural Network
assignment that the quality of fit from training a neural network
depends largely on the hyperparameters used to define it.

The code below is taken from Assignment \#4, where we looked at
predicting some timestep of given data for a Lorenz attractor. These
functions are used to create and train a keras model for some given set
of hyperparameters, and then compute the mean-square error by comparing
to the actual data.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k}{def} \PY{n+nf}{create\PYZus{}model}\PY{p}{(}\PY{n}{nodes}\PY{o}{=}\PY{p}{[}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{11}\PY{p}{,}\PY{l+m+mi}{6}\PY{p}{]}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}}
        \PY{l+s+sd}{    This function creates a dense Keras model with connectivity:}
        \PY{l+s+sd}{    3\PYZhy{}nodes\PYZhy{}3 where nodes represents the \PYZdq{}deep\PYZdq{} layers.}
        \PY{l+s+sd}{    }
        \PY{l+s+sd}{    Args:}
        \PY{l+s+sd}{        nodes: List describing number of deep layers and number of nodes at}
        \PY{l+s+sd}{               each layer. }
        \PY{l+s+sd}{        }
        \PY{l+s+sd}{    Return:}
        \PY{l+s+sd}{        model: Dense Keras model with desired connectivity.}
        \PY{l+s+sd}{    }
        \PY{l+s+sd}{    \PYZsq{}\PYZsq{}\PYZsq{}}
            \PY{c+c1}{\PYZsh{}Create model}
            \PY{n}{model} \PY{o}{=} \PY{n}{Sequential}\PY{p}{(}\PY{p}{)}
            
            \PY{c+c1}{\PYZsh{}Define input layer}
            \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{n}{nodes}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{input\PYZus{}dim}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
            
            \PY{c+c1}{\PYZsh{}Define \PYZdq{}deep\PYZdq{} layers}
            \PY{k}{for} \PY{n}{n} \PY{o+ow}{in} \PY{n}{nodes}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{:}\PY{p}{]}\PY{p}{:}
                
                \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{n}{n}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
            
            \PY{c+c1}{\PYZsh{}Define output layer}
            \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{linear}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)} \PY{c+c1}{\PYZsh{}sigmoid\PYZsq{}))}
        
            \PY{c+c1}{\PYZsh{}Compile model}
            \PY{n}{model}\PY{o}{.}\PY{n}{compile}\PY{p}{(}\PY{n}{loss}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mean\PYZus{}squared\PYZus{}error}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{optimizer}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{adam}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            
            \PY{k}{return} \PY{n}{model}
        
        \PY{k}{def} \PY{n+nf}{train\PYZus{}model}\PY{p}{(}\PY{n}{model}\PY{p}{,}\PY{n}{xyz}\PY{p}{,}\PY{n}{epochs} \PY{o}{=} \PY{l+m+mi}{999}\PY{p}{,}\PY{n}{L}\PY{o}{=}\PY{l+m+mi}{900}\PY{p}{,}\PY{n}{ndt}\PY{o}{=}\PY{l+m+mi}{99}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}}
        \PY{l+s+sd}{    This function trains a given Keras model to shift a time series}
        \PY{l+s+sd}{    forward by some timestep ndt.}
        \PY{l+s+sd}{    }
        \PY{l+s+sd}{    Args:}
        \PY{l+s+sd}{        model: Keras model}
        \PY{l+s+sd}{        ndt: Timestep to shift time series}
        \PY{l+s+sd}{        xyz: 3D time series data}
        \PY{l+s+sd}{        L: Length of training interval}
        \PY{l+s+sd}{        epochs: Number of epochs to perform training}
        \PY{l+s+sd}{        }
        \PY{l+s+sd}{    Return:}
        \PY{l+s+sd}{        model: Trained model}
        \PY{l+s+sd}{    }
        \PY{l+s+sd}{    \PYZsq{}\PYZsq{}\PYZsq{}}
            
            \PY{n}{history} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{xyz}\PY{p}{[}\PY{p}{:}\PY{n}{L}\PY{p}{]}\PY{p}{,}\PY{n}{xyz}\PY{p}{[}\PY{n}{ndt}\PY{p}{:}\PY{n}{L}\PY{o}{+}\PY{n}{ndt}\PY{p}{]}\PY{p}{,} \PY{n}{epochs}\PY{o}{=}\PY{n}{epochs}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,} 
                                \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
            
            \PY{k}{return} \PY{n}{model}
        
        \PY{k}{def} \PY{n+nf}{mean\PYZus{}square}\PY{p}{(}\PY{n}{args}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}}
        \PY{l+s+sd}{    This function will compute the mean\PYZhy{}squared error of a keras model with given hyperparameters,}
        \PY{l+s+sd}{    that attempt to predict some time shift in the given data set.}
        \PY{l+s+sd}{    }
        \PY{l+s+sd}{    Args:}
        \PY{l+s+sd}{        args = [nodes,epochs,xyz]}
        \PY{l+s+sd}{            nodes is the list specifying the connectivity of the keras model}
        \PY{l+s+sd}{            epochs is the number of training epochs}
        \PY{l+s+sd}{            xyz is the 3 dimensional data set}
        \PY{l+s+sd}{        }
        \PY{l+s+sd}{    Return:}
        \PY{l+s+sd}{        Mean squared error}
        \PY{l+s+sd}{    }
        \PY{l+s+sd}{    \PYZsq{}\PYZsq{}\PYZsq{}}
            
            \PY{n}{vs}\PY{p}{,} \PY{n}{ndt}\PY{p}{,} \PY{n}{L} \PY{o}{=} \PY{l+m+mi}{5000}\PY{p}{,} \PY{l+m+mi}{99}\PY{p}{,} \PY{l+m+mi}{900}
            \PY{n}{nodes}\PY{p}{,}\PY{n}{epochs}\PY{p}{,}\PY{n}{xyz} \PY{o}{=} \PY{n}{args}
            \PY{n}{mod} \PY{o}{=} \PY{n}{create\PYZus{}model}\PY{p}{(}\PY{n}{nodes} \PY{o}{=} \PY{n}{nodes}\PY{p}{)}
            \PY{n}{mod} \PY{o}{=} \PY{n}{train\PYZus{}model}\PY{p}{(}\PY{n}{mod}\PY{p}{,}\PY{n}{xyz}\PY{p}{,}\PY{n}{epochs} \PY{o}{=} \PY{n}{epochs}\PY{p}{)}
            
            \PY{k}{return} \PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(} \PY{p}{(}\PY{n}{xyz}\PY{p}{[}\PY{n}{vs}\PY{o}{+}\PY{n}{ndt}\PY{p}{:}\PY{n}{vs}\PY{o}{+}\PY{n}{L}\PY{o}{+}\PY{n}{ndt}\PY{p}{,}\PY{p}{:}\PY{p}{]}\PY{o}{\PYZhy{}}\PY{n}{mod}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{xyz}\PY{p}{[}\PY{n}{vs}\PY{p}{:}\PY{n}{vs}\PY{o}{+}\PY{n}{L}\PY{p}{]}\PY{p}{)} \PY{p}{)}\PY{o}{*}\PY{o}{*}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    The following block of code will generate the Lorenz attractor
trajectory that was studied in Assignment \#4.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}9}]:} \PY{k}{def} \PY{n+nf}{dfunc}\PY{p}{(}\PY{n}{state}\PY{p}{,} \PY{n}{t0}\PY{p}{,} \PY{n}{sigma}\PY{o}{=}\PY{l+m+mf}{10.0}\PY{p}{,} \PY{n}{beta}\PY{o}{=}\PY{l+m+mi}{8}\PY{o}{/}\PY{l+m+mf}{3.0}\PY{p}{,} \PY{n}{rho}\PY{o}{=}\PY{l+m+mf}{58.0}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZsq{}\PYZsq{}\PYZsq{}}
        \PY{l+s+sd}{    This returns the time derivative of the coordinates,}
        \PY{l+s+sd}{    defined by the 3D Lorenz system:}
        \PY{l+s+sd}{    dx/dt = sigma*(y\PYZhy{}x)}
        \PY{l+s+sd}{    dy/dt = x*(rho\PYZhy{}z)\PYZhy{}y}
        \PY{l+s+sd}{    dz/dt = x*y\PYZhy{}beta*z}
        \PY{l+s+sd}{    }
        \PY{l+s+sd}{    Args:}
        \PY{l+s+sd}{        state: array of length 3, coordinates at time t0}
        \PY{l+s+sd}{        t0: Time}
        \PY{l+s+sd}{        sigma, beta, rho: Lorentz system parameters}
        \PY{l+s+sd}{        }
        \PY{l+s+sd}{    Return:}
        \PY{l+s+sd}{        d/dt state: array, Time derivative of coordinates}
        \PY{l+s+sd}{    }
        \PY{l+s+sd}{    \PYZsq{}\PYZsq{}\PYZsq{}}
            
            \PY{c+c1}{\PYZsh{}Unpack state vector}
            \PY{n}{x}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{z} \PY{o}{=} \PY{n}{state}
            
            \PY{k}{return} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[} \PY{n}{sigma}\PY{o}{*}\PY{p}{(}\PY{n}{y}\PY{o}{\PYZhy{}}\PY{n}{x}\PY{p}{)}\PY{p}{,} \PY{n}{x}\PY{o}{*}\PY{p}{(}\PY{n}{rho}\PY{o}{\PYZhy{}}\PY{n}{z}\PY{p}{)}\PY{o}{\PYZhy{}}\PY{n}{y}\PY{p}{,} \PY{n}{x}\PY{o}{*}\PY{n}{y}\PY{o}{\PYZhy{}}\PY{n}{beta}\PY{o}{*}\PY{n}{z}\PY{p}{]}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{}Define time interval of interest}
        \PY{n}{t0}\PY{p}{,} \PY{n}{tf}\PY{p}{,} \PY{n}{tstep} \PY{o}{=} \PY{l+m+mf}{0.0}\PY{p}{,} \PY{l+m+mf}{20.0}\PY{p}{,} \PY{l+m+mi}{9999}
        \PY{n}{tvals} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{n}{t0}\PY{p}{,} \PY{n}{tf}\PY{p}{,} \PY{n}{tstep}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{}Set initial state set to [1,1,1]}
        \PY{n}{xyz\PYZus{}0} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{ones}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{}Integrate Lorenz system over time interval}
        \PY{n}{xyz} \PY{o}{=} \PY{n}{scipy}\PY{o}{.}\PY{n}{integrate}\PY{o}{.}\PY{n}{odeint}\PY{p}{(} \PY{n}{dfunc}\PY{p}{,} \PY{n}{xyz\PYZus{}0}\PY{p}{,} \PY{n}{tvals} \PY{p}{)}
\end{Verbatim}


    It will be a good idea to store the number of cores, as this will most
likely be the optimal number of processes to run simultaneously.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{c+c1}{\PYZsh{}Count number of cores}
        \PY{n}{NCPU} \PY{o}{=} \PY{n}{psutil}\PY{o}{.}\PY{n}{cpu\PYZus{}count}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    The hyperparameters of interest in this report are the number of layers,
the number of nodes per layer, and the number of epochs during the
training cycle. Starting with the number of layers, we can use the
multiprocessing Pool object to compute the mean squared error for models
trained with varying depth. Such tasks are computationally demanding,
and each are independent of another, making this a good candidate to
parallelize.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}10}]:} \PY{c+c1}{\PYZsh{}List node schemes with varying number of layers}
         \PY{n}{num\PYZus{}layers} \PY{o}{=} \PY{p}{[}\PY{p}{[}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{,}\PY{p}{[}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{,}\PY{p}{[}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{,}\PY{p}{[}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{,}\PY{p}{[}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{]}
         
         \PY{c+c1}{\PYZsh{}Number of training epochs}
         \PY{n}{epochs} \PY{o}{=} \PY{l+m+mi}{999}
         
         \PY{c+c1}{\PYZsh{}Pack into argument list}
         \PY{n}{n\PYZus{}lay} \PY{o}{=} \PY{p}{[}\PY{p}{[}\PY{n}{num\PYZus{}layers}\PY{p}{[}\PY{n}{j}\PY{p}{]}\PY{p}{,}\PY{n}{epochs}\PY{p}{,}\PY{n}{xyz}\PY{p}{]} \PY{k}{for} \PY{n}{j} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{num\PYZus{}layers}\PY{p}{)}\PY{p}{)}\PY{p}{]}
         
         \PY{c+c1}{\PYZsh{}Run in parallel, with NCPU=4 processes running simultaneously}
         \PY{k}{if} \PY{n+nv+vm}{\PYZus{}\PYZus{}name\PYZus{}\PYZus{}} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZus{}\PYZus{}main\PYZus{}\PYZus{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
             
             \PY{k}{with} \PY{n}{Pool}\PY{p}{(}\PY{n}{NCPU}\PY{p}{)} \PY{k}{as} \PY{n}{p}\PY{p}{:}
                 \PY{n}{m\PYZus{}square} \PY{o}{=} \PY{n}{p}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{n}{mean\PYZus{}square}\PY{p}{,} \PY{n}{n\PYZus{}lay}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{}Print results}
         \PY{k}{for} \PY{n}{j} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{m\PYZus{}square}\PY{p}{)}\PY{p}{)}\PY{p}{:}
             
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Network: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{ leads to a mean\PYZhy{}square error of: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}
                               \PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{num\PYZus{}layers}\PY{p}{[}\PY{n}{j}\PY{p}{]}\PY{p}{,}\PY{n}{m\PYZus{}square}\PY{p}{[}\PY{n}{j}\PY{p}{]}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Network: [5, 8, 5] leads to a mean-square error of: 9.108114893243906
Network: [5, 8, 8, 5] leads to a mean-square error of: 6.588264695195615
Network: [5, 8, 8, 8, 5] leads to a mean-square error of: 6.719830008721107
Network: [5, 8, 8, 8, 8, 5] leads to a mean-square error of: 7.998176976720634
Network: [5, 8, 8, 8, 8, 8, 5] leads to a mean-square error of: 3.0376666523178124

    \end{Verbatim}

    We see that increasing the model depth tends produce better models. This
is most likely a result of the versatility of the model getting better
with a more complex topology. Next, we consider the optimum model with 7
layers, and vary the number of nodes per layer.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}11}]:} \PY{c+c1}{\PYZsh{}List node schemes with varying number of nodes per layer}
         \PY{n}{layer\PYZus{}depth} \PY{o}{=} \PY{p}{[}\PY{p}{[}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{,}\PY{p}{[}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{10}\PY{p}{,}\PY{l+m+mi}{12}\PY{p}{,}\PY{l+m+mi}{14}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{,}\PY{p}{[}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{16}\PY{p}{,}\PY{l+m+mi}{16}\PY{p}{,}\PY{l+m+mi}{16}\PY{p}{,}\PY{l+m+mi}{16}\PY{p}{,}\PY{l+m+mi}{16}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{]}
         
         \PY{c+c1}{\PYZsh{}Number of training epochs}
         \PY{n}{epochs} \PY{o}{=} \PY{l+m+mi}{999}
         
         \PY{c+c1}{\PYZsh{}Pack into argument list}
         \PY{n}{n\PYZus{}lay} \PY{o}{=} \PY{p}{[}\PY{p}{[}\PY{n}{layer\PYZus{}depth}\PY{p}{[}\PY{n}{j}\PY{p}{]}\PY{p}{,}\PY{n}{epochs}\PY{p}{,}\PY{n}{xyz}\PY{p}{]} \PY{k}{for} \PY{n}{j} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{layer\PYZus{}depth}\PY{p}{)}\PY{p}{)}\PY{p}{]}
         
         \PY{c+c1}{\PYZsh{}Run in parallel, with NCPU=4 processes running simultaneously}
         \PY{k}{if} \PY{n+nv+vm}{\PYZus{}\PYZus{}name\PYZus{}\PYZus{}} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZus{}\PYZus{}main\PYZus{}\PYZus{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
             
             \PY{k}{with} \PY{n}{Pool}\PY{p}{(}\PY{n}{NCPU}\PY{p}{)} \PY{k}{as} \PY{n}{p}\PY{p}{:}
                 \PY{n}{m\PYZus{}square} \PY{o}{=} \PY{n}{p}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{n}{mean\PYZus{}square}\PY{p}{,} \PY{n}{n\PYZus{}lay}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{}Print results}
         \PY{k}{for} \PY{n}{j} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{m\PYZus{}square}\PY{p}{)}\PY{p}{)}\PY{p}{:}
             
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Network: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{ leads to a mean\PYZhy{}square error of: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}
                               \PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{layer\PYZus{}depth}\PY{p}{[}\PY{n}{j}\PY{p}{]}\PY{p}{,}\PY{n}{m\PYZus{}square}\PY{p}{[}\PY{n}{j}\PY{p}{]}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Network: [5, 2, 2, 5, 2, 2, 5] leads to a mean-square error of: 29.481753537461103
Network: [5, 8, 10, 12, 14, 8, 5] leads to a mean-square error of: 10.21615628181107
Network: [5, 16, 16, 16, 16, 16, 5] leads to a mean-square error of: 29.481753537461103

    \end{Verbatim}

    Interestingly, we see that the second model produces the best results.
It seems that an increased number of nodes per layer will train better
models, however, it is reasonable to assume that larger models will take
longer to train. It follows that, when keeping the number of training
epochs fixed, there will be some optimal number of nodes that can be
trained efficiently. Finally, we look at how the results change with the
number of training epochs.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}12}]:} \PY{c+c1}{\PYZsh{}Fix node scheme}
         \PY{n}{layer} \PY{o}{=} \PY{p}{[}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{16}\PY{p}{,}\PY{l+m+mi}{16}\PY{p}{,}\PY{l+m+mi}{16}\PY{p}{,}\PY{l+m+mi}{16}\PY{p}{,}\PY{l+m+mi}{16}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{]}
         
         \PY{c+c1}{\PYZsh{}List varying number of training epochs}
         \PY{n}{num\PYZus{}epochs} \PY{o}{=} \PY{p}{[}\PY{l+m+mi}{599}\PY{p}{,}\PY{l+m+mi}{999}\PY{p}{,}\PY{l+m+mi}{1499}\PY{p}{,}\PY{l+m+mi}{1999}\PY{p}{]}
         
         \PY{c+c1}{\PYZsh{}Pack into argument list}
         \PY{n}{n\PYZus{}lay} \PY{o}{=} \PY{p}{[}\PY{p}{[}\PY{n}{layer}\PY{p}{,}\PY{n}{num\PYZus{}epochs}\PY{p}{[}\PY{n}{j}\PY{p}{]}\PY{p}{,}\PY{n}{xyz}\PY{p}{]} \PY{k}{for} \PY{n}{j} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{num\PYZus{}epochs}\PY{p}{)}\PY{p}{)}\PY{p}{]}
         
         \PY{c+c1}{\PYZsh{}Run in parallel, with NCPU=4 processes running simultaneously}
         \PY{k}{if} \PY{n+nv+vm}{\PYZus{}\PYZus{}name\PYZus{}\PYZus{}} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZus{}\PYZus{}main\PYZus{}\PYZus{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
             
             \PY{k}{with} \PY{n}{Pool}\PY{p}{(}\PY{n}{NCPU}\PY{p}{)} \PY{k}{as} \PY{n}{p}\PY{p}{:}
                 \PY{n}{m\PYZus{}square} \PY{o}{=} \PY{n}{p}\PY{o}{.}\PY{n}{map}\PY{p}{(}\PY{n}{mean\PYZus{}square}\PY{p}{,} \PY{n}{n\PYZus{}lay}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{}Print results}
         \PY{k}{for} \PY{n}{j} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{m\PYZus{}square}\PY{p}{)}\PY{p}{)}\PY{p}{:}
             
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{ Epochs leads to a mean\PYZhy{}square error of: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}
                               \PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{num\PYZus{}epochs}\PY{p}{[}\PY{n}{j}\PY{p}{]}\PY{p}{,}\PY{n}{m\PYZus{}square}\PY{p}{[}\PY{n}{j}\PY{p}{]}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
599 Epochs leads to a mean-square error of: 31.357054918189938
999 Epochs leads to a mean-square error of: 29.481753537461103
1499 Epochs leads to a mean-square error of: 27.201603001270552
1999 Epochs leads to a mean-square error of: 24.980007423519613

    \end{Verbatim}

    As we see, the model becomes better trained with a larger number of
training epochs. This is not too surprising, as the data will likely
take a while to propagate through such a large neural network. Through
all of the hyperparameters explored, we see that the {[}5,8,8,8,8,8,5{]}
model produced the lowest mean square error. In this sense, it seems
that the accuaracy of the neural network favours a large number of
layers, with a reasonable low number of nodes per layer. These were
analyzed at a fixed number of epochs, which seems to suggest that
information is able to propagate through a network much more efficiently
with a fewer number of nodes per layer.

    \hypertarget{conclusion}{%
\subsubsection{Conclusion}\label{conclusion}}

    This notebook has examined the practice of parallel computing in python
using multiprocessing, and how the efficiency of spawning multiple
processes relates to how many processes we call. We saw that the CPU
efficiency per process tends to get better and asymptote as the number
of processes increases. This most likely is a result of the available
hardware (i.e.~number of cores), which would intuitively saturate and
behave as if the tasks were being executed sequentially. Additionally,
we looked at how parallel computing can be used for the application of
hyperparameter optimization of neural networks, a task which is
generally quite computationally demanding. Using a brute-force type
approach, we were able to compare how the model accuract varies when
changing different hyperparameters, and we were able to do this in a
reasonable amound of time by exploiting the multiple cores available to
us.

With more time available, it would be very interesting to see how these
tasks could be distributed across an entire network of CPUs, rather than
just a single device, a technique known as cluster computing.


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
