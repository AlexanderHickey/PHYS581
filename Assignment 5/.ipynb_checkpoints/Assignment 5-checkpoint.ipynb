{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phys 581 Winter 2019\n",
    "# Assignment #5: Multiprocessing\n",
    "## Alexander Hickey, 10169582"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this notebook makes use of the Keras deep learning library for python, which is compatible only with Python 2.7-3.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.16 |Anaconda, Inc.| (default, Mar 14 2019, 21:00:58) \\n[GCC 7.3.0]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Must be running Python 3.6 or lower!\n",
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import useful libraries\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.integrate\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os\n",
    "import signal, subprocess\n",
    "import psutil\n",
    "from multiprocessing import Pool\n",
    "#from keras.models import Model, Sequential\n",
    "#from keras.layers import Input, Dense\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel computing allows one to harness the processing power of a multi-core computer, and can significantly decrease the time required for repetitive computations. The idea behind parallel computing is to take a large problem and divide it into smaller ones which can be solved simultaneously, and allocate these different tasks to different parts of the CPU network. Often times, it is very powerful to implement parallel computing in the framework of scientific computations, to allow researchers to execute code and analyze output within a reasonable timeframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( psutil.cpu_stats(), '\\n' )\n",
    "print( psutil.cpu_times(), '\\n' )\n",
    "print( psutil.cpu_times_percent(interval=1, percpu=False), '\\n' )\n",
    "print( 'number of physical(?) CPUs: ', psutil.cpu_count(), '\\n' )\n",
    "print( psutil.cpu_times_percent(interval=1, percpu=True), '\\n' )\n",
    "print(sys.argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpu_idle(nloop=999):\n",
    "    \"\"\" simple example of signal handling\n",
    "    \"\"\"\n",
    "    cpu_idle.flag = nloop\n",
    "    \n",
    "    def handler(signum, frame):\n",
    "        print('Signal handler called with signal ',signum)\n",
    "        #signal.alarm(0)\n",
    "        cpu_idle.flag = 0\n",
    "        \n",
    "    signal.signal(signal.SIGINT, handler)\n",
    "\n",
    "    while cpu_idle.flag > 0:\n",
    "        cpu_idle.flag -= 1\n",
    "        cpu = psutil.cpu_times_percent(interval=1, percpu=True)\n",
    "        print('\\t'.join([str(c.idle) for c in cpu]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a simple CPU intensive task\n",
    "#\n",
    "cmnd = '[i**2 for i in range(9876543)]'\n",
    "%timeit exec(cmnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spawn a subprocess to execute the task\n",
    "#\n",
    "status = subprocess.check_output('python -c \"[i**2 for i in range(9876)]; print(True)\"',shell=True)\n",
    "print('subprocess status: ', status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmnd = 'python -c \"[i**2 for i in range(9876543)]; print(True)\"'\n",
    "import time\n",
    "def paralize(cmdlist, nwait=100, nicer=False):\n",
    "    \n",
    "    plist = []\n",
    "    for n, cmd in enumerate(cmdlist):\n",
    "        plist.append( subprocess.Popen(cmnd, shell=True) ) \n",
    "    \n",
    "    tlist = {}\n",
    "    n0 = time.time()\n",
    "    for i in range(nwait):\n",
    "        \n",
    "        time.sleep(0.1)\n",
    "        \n",
    "        for n,p in enumerate(plist):    \n",
    "            try:\n",
    "                parent = psutil.Process(pid=p.pid)\n",
    "        \n",
    "                child = parent.children()[0]\n",
    "                \n",
    "                if child is None:# or len(child)< 1:\n",
    "                    continue\n",
    "                proc = psutil.Process(pid=child.pid)\n",
    "                \n",
    "                cputime = proc.cpu_times().user\n",
    "                \n",
    "                tlist[p.pid] = [time.time()-n0,cputime]\n",
    "        \n",
    "            except:\n",
    "                None\n",
    "                \n",
    "        \n",
    "    return tlist\n",
    "        \n",
    "dat = paralize([cmnd for j in range(8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t =[]\n",
    "for key in dat:\n",
    "    t.append(dat[key])\n",
    "t = np.array(t)\n",
    "\n",
    "plt.plot(t[:,0],t[:,1],marker= 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(t[:,1])/np.mean(t[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run three subprocesses in parallel\n",
    "#\n",
    "paralize([cmnd for i in range(3)], nwait=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run one process for each CPU\n",
    "#\n",
    "paralize([cmnd for i in range(8)], nwait=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversubscribing by 50% takes slightly longer\n",
    "#\n",
    "paralize([cmnd for i in range(12)], nwait=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paralize([cmnd for i in range(24)], nwait=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: determine scaling efficiency\n",
    "Gather estimates of computation as a function of number of processes, plot, and analyze.\n",
    "\n",
    "Ideally we would have a perfectly linear relationship up to the number of CPUs and constant thereafter.  In practice the slope will be less than one and may saturate earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmdlist = [cmnd for j in range(5)]\n",
    "for n, cmd in enumerate(cmdlist):\n",
    "    print(n,cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmnd = 'python -c \"[i**2 for i in range(9876543)]; print(True)\"'\n",
    "\n",
    "def time_par(cmdlist, time_res = 1e-5):\n",
    "    '''\n",
    "    This function will compute both the ...    \n",
    "    Args:\n",
    "        cmdlist: List of commands to track\n",
    "        time_res: Time step between tracking\n",
    "        \n",
    "    Return:\n",
    "        tlist: Array of both wall and cpu times for each process\n",
    "               to terminate. Axis 0 corresponds to wall time,\n",
    "               axis 1 corresponds to cpu time.\n",
    "    \n",
    "    '''\n",
    "    plist = [subprocess.Popen(cmnd, shell=True) for j in cmdlist]\n",
    "    ch_list = [0.0] \n",
    "    t0 = time.time()\n",
    "    t_dict = {p.pid:0.0 for p in plist}\n",
    "    \n",
    "    \n",
    "    while ch_list != []:\n",
    "        \n",
    "        ch_list = []\n",
    "        time.sleep(time_res)\n",
    "        \n",
    "        for p in plist:    \n",
    "            \n",
    "            parent = psutil.Process(pid=p.pid)\n",
    "            child = parent.children()\n",
    "            \n",
    "            try:\n",
    "                proc = psutil.Process(pid=child[0].pid)\n",
    "                cputime = proc.cpu_times().user\n",
    "                t_dict[p.pid] = [time.time()-t0,cputime]\n",
    "                ch_list.append(child)\n",
    "                \n",
    "            except:\n",
    "                None\n",
    "    \n",
    "    t = np.array([t_dict[key] for key in t_dict ])\n",
    "    \n",
    "    return t\n",
    "\n",
    "def ratio(t):\n",
    "    \n",
    "    \n",
    "    return np.mean(t[:,1])/np.max(t[:,0])\n",
    "\n",
    "\n",
    "    \n",
    "t=time_par([cmnd for j in range(2)])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.315/2.47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 7\n",
    "t_rat = []\n",
    "\n",
    "for k in range(2,N+1):\n",
    "    \n",
    "    t = time_par([cmnd for j in range(k)])\n",
    "    \n",
    "    t_rat.append(ratio(t))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(np.arange(2,N+1),t_rat,marker= 'o')\n",
    "plt.xlabel('N')\n",
    "plt.ylabel('wall/cpu')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Use the multiprocessing package to speed up hyperparameter optimization.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(nodes=[8,11,6]):\n",
    "    '''\n",
    "    This function creates a dense Keras model with connectivity:\n",
    "    3-nodes-3 where nodes represents the \"deep\" layers.\n",
    "    \n",
    "    Args:\n",
    "        nodes: List describing number of deep layers and number of nodes at\n",
    "               each layer. \n",
    "        \n",
    "    Return:\n",
    "        model: Dense Keras model with desired connectivity.\n",
    "    \n",
    "    '''\n",
    "    #Create model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Define input layer\n",
    "    model.add(Dense(nodes[0], input_dim=3, activation='relu'))\n",
    "    \n",
    "    #Define \"deep\" layers\n",
    "    for n in nodes[1:]:\n",
    "        \n",
    "        model.add(Dense(n, activation='relu'))\n",
    "    \n",
    "    #Define output layer\n",
    "    model.add(Dense(3, activation='linear')) #sigmoid'))\n",
    "\n",
    "    #Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(model,xyz,epochs = 999,L=900,ndt=99):\n",
    "    '''\n",
    "    This function trains a given Keras model to shift a time series\n",
    "    forward by some timestep ndt.\n",
    "    \n",
    "    Args:\n",
    "        model: Keras model\n",
    "        ndt: Timestep to shift time series\n",
    "        xyz: 3D time series data\n",
    "        L: Length of training interval\n",
    "        epochs: Number of epochs to perform training\n",
    "        \n",
    "    Return:\n",
    "        model: Trained model\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    history = model.fit(xyz[:L],xyz[ndt:L+ndt], epochs=epochs, batch_size=100, \n",
    "                        verbose=0)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def mean_square(args):\n",
    "    '''\n",
    "    args = [nodes,epochs,xyz]\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    vs, ndt, L = 5000, 99, 900\n",
    "    nodes,epochs,xyz = args\n",
    "    mod = create_model(nodes = nodes)\n",
    "    mod = train_model(mod,xyz,epochs = epochs)\n",
    "    \n",
    "    return np.sqrt( np.mean( (xyz[vs+ndt:vs+L+ndt,:]-mod.predict(xyz[vs:vs+L]) )**2))\n",
    "\n",
    "NCPU = psutil.cpu_count()\n",
    "print('Number of CPUs: '+str(NCPU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfunc(state, t0, sigma=10.0, beta=8/3.0, rho=58.0):\n",
    "    '''\n",
    "    This returns the time derivative of the coordinates,\n",
    "    defined by the 3D Lorenz system:\n",
    "    dx/dt = sigma*(y-x)\n",
    "    dy/dt = x*(rho-z)-y\n",
    "    dz/dt = x*y-beta*z\n",
    "    \n",
    "    Args:\n",
    "        state: array of length 3, coordinates at time t0\n",
    "        t0: Time\n",
    "        sigma, beta, rho: Lorentz system parameters\n",
    "        \n",
    "    Return:\n",
    "        d/dt state: array, Time derivative of coordinates\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #Unpack state vector\n",
    "    x, y, z = state\n",
    "    \n",
    "    return np.array([ sigma*(y-x), x*(rho-z)-y, x*y-beta*z])\n",
    "\n",
    "#Define time interval of interest\n",
    "t0, tf, tstep = 0.0, 20.0, 9999\n",
    "tvals = np.linspace(t0, tf, tstep)\n",
    "\n",
    "#Set initial state set to [1,1,1]\n",
    "xyz_0 = np.ones(3)\n",
    "\n",
    "#Integrate Lorenz system over time interval\n",
    "xyz = scipy.integrate.odeint( dfunc, xyz_0, tvals )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = [[5,8,5],[5,8,8,5],[5,8,8,8,5],[5,8,8,8,8,5],[5,8,8,8,8,8,5]]\n",
    "epochs = 999\n",
    "n_lay = [[num_layers[j],epochs,xyz] for j in range(len(num_layers))]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    with Pool(NCPU) as p:\n",
    "        m_square = p.map(mean_square, n_lay)\n",
    "        \n",
    "print(m_square)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel python\n",
    "https://www.parallelpython.com/  \n",
    "\n",
    "### Figure out how to get this working on a single computer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'local': 4}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pp\n",
    "ppservers=('munin','noatun','branstock')\n",
    "\n",
    "job_server = pp.Server(ppservers = ppservers)\n",
    "job_server.get_active_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 8.00914287567\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def f(x):\n",
    "    \n",
    "    time.sleep(.5)\n",
    "    \n",
    "    return None\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "inputs = (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16)\n",
    "for i in inputs:\n",
    "    \n",
    "    f(i)\n",
    "    \n",
    "t = time.time()-t0\n",
    "    \n",
    "print('Time: ' +str(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "Time: 0.0025839805603\n",
      "Job execution statistics:\n",
      " job count | % of all jobs | job time sum | time per job | job server\n",
      "         1 |         12.50 |       0.0000 |     0.000000 | munin:60000\n",
      "         2 |         25.00 |       0.0000 |     0.000000 | noatun:60000\n",
      "         4 |         50.00 |       0.0000 |     0.000000 | local\n",
      "         1 |         12.50 |       0.0000 |     0.000000 | branstock:60000\n",
      "Time elapsed since server creation 9.8854060173\n",
      "4 active tasks, 4 cores\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def f(x):\n",
    "    \n",
    "    time.sleep(1.0)\n",
    "    \n",
    "    return x\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "inputs = (1,2,3,4,5,6,7,8)\n",
    "jobs = [(i, job_server.submit(f,(i,), modules = (\"time\",))) for i in inputs]\n",
    "for i, job in jobs:\n",
    "    print i\n",
    "\n",
    "t = time.time()-t0\n",
    "    \n",
    "print('Time: ' +str(t))\n",
    "job_server.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure out how to get this working on all of the ST026 computers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'branstock:60000': 4, 'local': 4, 'munin:60000': 4, 'noatun:60000': 4}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_server.get_active_nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
